{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU name:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n   age  affordibility  bought_insurance\n0   22              1                 0\n1   25              0                 0\n2   47              1                 1\n3   52              0                 0\n4   46              1                 1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(28, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "df = pd.read_csv(f\"{os.path.dirname(os.path.abspath('__file__'))}\\\\4_insurance_data.csv\")\n",
    "print(df.head())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     age  affordibility\n",
       "2   0.47              1\n",
       "10  0.18              1\n",
       "21  0.26              0\n",
       "11  0.28              1\n",
       "14  0.49              1\n",
       "9   0.61              1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>affordibility</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.47</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.18</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.26</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.28</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.49</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.61</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# split train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['age','affordibility']],df.bought_insurance,test_size=0.2, random_state=25)\n",
    "\n",
    "# apply scaling\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled['age'] = X_train_scaled['age'] / 100\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled['age'] = X_test_scaled['age'] / 100\n",
    "\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "Epoch 4803/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.9091\n",
      "Epoch 4804/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.9091\n",
      "Epoch 4805/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.9091\n",
      "Epoch 4806/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9091\n",
      "Epoch 4807/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9091\n",
      "Epoch 4808/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9091\n",
      "Epoch 4809/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.9091\n",
      "Epoch 4810/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9091\n",
      "Epoch 4811/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9091\n",
      "Epoch 4812/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.9091\n",
      "Epoch 4813/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.9091\n",
      "Epoch 4814/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.9091\n",
      "Epoch 4815/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9091\n",
      "Epoch 4816/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.9091\n",
      "Epoch 4817/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.9091\n",
      "Epoch 4818/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.9091\n",
      "Epoch 4819/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.9091\n",
      "Epoch 4820/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.9091\n",
      "Epoch 4821/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9091\n",
      "Epoch 4822/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9091\n",
      "Epoch 4823/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9091\n",
      "Epoch 4824/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9091\n",
      "Epoch 4825/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9091\n",
      "Epoch 4826/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9091\n",
      "Epoch 4827/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9091\n",
      "Epoch 4828/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9091\n",
      "Epoch 4829/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9091\n",
      "Epoch 4830/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.9091\n",
      "Epoch 4831/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9091\n",
      "Epoch 4832/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9091\n",
      "Epoch 4833/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.9091\n",
      "Epoch 4834/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9091\n",
      "Epoch 4835/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.9091\n",
      "Epoch 4836/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.9091\n",
      "Epoch 4837/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.9091\n",
      "Epoch 4838/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.9091\n",
      "Epoch 4839/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.9091\n",
      "Epoch 4840/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.9091\n",
      "Epoch 4841/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9091\n",
      "Epoch 4842/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9091\n",
      "Epoch 4843/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9091\n",
      "Epoch 4844/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.9091\n",
      "Epoch 4845/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9091\n",
      "Epoch 4846/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.9091\n",
      "Epoch 4847/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9091\n",
      "Epoch 4848/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9091\n",
      "Epoch 4849/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9091\n",
      "Epoch 4850/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9091\n",
      "Epoch 4851/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4852/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4853/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4854/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4855/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4856/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9091\n",
      "Epoch 4857/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.9091\n",
      "Epoch 4858/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.9091\n",
      "Epoch 4859/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.9091\n",
      "Epoch 4860/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.9091\n",
      "Epoch 4861/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.9091\n",
      "Epoch 4862/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.9091\n",
      "Epoch 4863/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.9091\n",
      "Epoch 4864/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.9091\n",
      "Epoch 4865/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.9091\n",
      "Epoch 4866/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.9091\n",
      "Epoch 4867/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.9091\n",
      "Epoch 4868/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.9091\n",
      "Epoch 4869/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.9091\n",
      "Epoch 4870/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.9091\n",
      "Epoch 4871/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.9091\n",
      "Epoch 4872/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.9091\n",
      "Epoch 4873/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.9091\n",
      "Epoch 4874/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.9091\n",
      "Epoch 4875/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.9091\n",
      "Epoch 4876/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.9091\n",
      "Epoch 4877/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.9091\n",
      "Epoch 4878/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.9091\n",
      "Epoch 4879/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.9091\n",
      "Epoch 4880/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.9091\n",
      "Epoch 4881/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.9091\n",
      "Epoch 4882/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.9091\n",
      "Epoch 4883/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.9091\n",
      "Epoch 4884/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.9091\n",
      "Epoch 4885/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.9091\n",
      "Epoch 4886/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.9091\n",
      "Epoch 4887/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9091\n",
      "Epoch 4888/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9091\n",
      "Epoch 4889/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9091\n",
      "Epoch 4890/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9091\n",
      "Epoch 4891/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9091\n",
      "Epoch 4892/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9091\n",
      "Epoch 4893/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9091\n",
      "Epoch 4894/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.9091\n",
      "Epoch 4895/5000\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4651 - accuracy: 0.9091\n",
      "Epoch 4896/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9091\n",
      "Epoch 4897/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4898/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4899/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4900/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4901/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4902/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9091\n",
      "Epoch 4903/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9091\n",
      "Epoch 4904/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9091\n",
      "Epoch 4905/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9091\n",
      "Epoch 4906/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9091\n",
      "Epoch 4907/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9091\n",
      "Epoch 4908/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.9091\n",
      "Epoch 4909/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9091\n",
      "Epoch 4910/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9091\n",
      "Epoch 4911/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9091\n",
      "Epoch 4912/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9091\n",
      "Epoch 4913/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9091\n",
      "Epoch 4914/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9091\n",
      "Epoch 4915/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9091\n",
      "Epoch 4916/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9091\n",
      "Epoch 4917/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9091\n",
      "Epoch 4918/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9091\n",
      "Epoch 4919/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9091\n",
      "Epoch 4920/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9091\n",
      "Epoch 4921/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.9091\n",
      "Epoch 4922/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9091\n",
      "Epoch 4923/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9091\n",
      "Epoch 4924/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9091\n",
      "Epoch 4925/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9091\n",
      "Epoch 4926/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.9091\n",
      "Epoch 4927/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9091\n",
      "Epoch 4928/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4929/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4930/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4931/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4932/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4933/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.9091\n",
      "Epoch 4934/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4935/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4936/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4937/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4938/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.9091\n",
      "Epoch 4939/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4940/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4941/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4942/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4943/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.9091\n",
      "Epoch 4944/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4945/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4946/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4947/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4948/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9091\n",
      "Epoch 4949/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4950/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4951/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4952/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4953/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9091\n",
      "Epoch 4954/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4955/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4956/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4957/5000\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4958/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4959/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9091\n",
      "Epoch 4960/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4961/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4962/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4963/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4964/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.9091\n",
      "Epoch 4965/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4966/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4967/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4968/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4969/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9091\n",
      "Epoch 4970/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4971/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4972/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4973/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4974/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9091\n",
      "Epoch 4975/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4976/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4977/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4978/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4979/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4980/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9091\n",
      "Epoch 4981/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4982/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4983/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4984/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4985/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9091\n",
      "Epoch 4986/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4987/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4988/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4989/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4990/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.9091\n",
      "Epoch 4991/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4992/5000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4993/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4994/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4995/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9091\n",
      "Epoch 4996/5000\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 4997/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 4998/5000\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 4999/5000\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.9091\n",
      "Epoch 5000/5000\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.9091\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x201f348a310>"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3550 - accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.35497748851776123, 1.0]"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test) # perfect model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([[5.060868],\n",
       "        [1.40865 ]], dtype=float32),\n",
       " array([-2.913703], dtype=float32))"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "coef, intercept = model.get_weights()\n",
    "coef, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# manual prediction funcion using sigmoid\n",
    "def prediction_function(age, affordibility):\n",
    "    return sigmoid(coef[0] * age + coef[1] * affordibility + intercept)\n",
    "\n",
    "def log_loss(y_actual, y_predicted):\n",
    "    eplison = 1e-15\n",
    "    y_predicted_new = np.array([min(max(i, eplison), 1 - eplison) for i in y_predicted])\n",
    "\n",
    "    return -np.mean(y_actual * np.log(y_predicted_new) + (1 - y_actual) * np.log(1 - y_predicted_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.7054848]\n",
      "[[0.7054848 ]\n",
      " [0.35569546]\n",
      " [0.16827849]\n",
      " [0.47801176]\n",
      " [0.7260697 ]\n",
      " [0.8294984 ]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction_function(0.47, 1))\n",
    "print(model.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0/500 - w1: 0.974907633470177 - w2: 0.948348125394529 - bias: -0.11341867736368583 - loss: 0.7113403233723417)\nEpoch: 50/500 - w1: 1.5033195541731388 - w2: 1.108384790367645 - bias: -1.2319047301235464 - loss: 0.5675865113475955)\nEpoch: 100/500 - w1: 2.200713131760032 - w2: 1.2941584023238903 - bias: -1.6607009122062801 - loss: 0.5390680417774752)\nEpoch: 150/500 - w1: 2.8495727769689085 - w2: 1.3696895491572745 - bias: -1.986105845859897 - loss: 0.5176462164249294)\nEpoch: 200/500 - w1: 3.443016970881803 - w2: 1.4042218624465033 - bias: -2.2571369883752723 - loss: 0.5005011269691375)\nEpoch: 250/500 - w1: 3.982450494649576 - w2: 1.4239127329321233 - bias: -2.494377365971801 - loss: 0.48654089537617085)\nEpoch: 300/500 - w1: 4.472179522095915 - w2: 1.438787986553552 - bias: -2.707387811922373 - loss: 0.4750814640632793)\nEpoch: 350/500 - w1: 4.917245868007634 - w2: 1.4525660781176122 - bias: -2.901176333556766 - loss: 0.46561475306999006)\nEpoch: 366/500 - w1: 5.051047623653049 - w2: 1.4569794548473887 - bias: -2.9596534546250037 - loss: 0.46293944095888917)\n"
     ]
    }
   ],
   "source": [
    "# custom (own) model\n",
    "class DNN:\n",
    "    def __init__(self):\n",
    "        self.w1 = 1\n",
    "        self.w2 = 1\n",
    "        self.bias = 0\n",
    "\n",
    "    def fit(self, X, y, epochs, loss_threshold):\n",
    "        self.w1, self.w2, self.bias = self.gradient_descent(X[\"age\"], X[\"affordibility\"], y, epochs, loss_threshold)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return sigmoid(self.w1 * X_test[\"age\"] + self.w2 * X_test[\"affordibility\"] + self.bias)\n",
    "\n",
    "    def gradient_descent(self, age, affordibility, y_actual, epochs, loss_threshold):\n",
    "        w1 = w2 = 1\n",
    "        bias, rate, n = 0, 0.5, len(age)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            weighted_sum = w1 * age + w2 * affordibility + bias\n",
    "\n",
    "            # predict and calculate loss\n",
    "            y_predicted = sigmoid(weighted_sum)\n",
    "            loss = log_loss(y_actual, y_predicted)\n",
    "\n",
    "            # use gradient descent to calculate weighted\n",
    "            w1d = (1/n) * np.dot(np.transpose(age), (y_predicted - y_actual))\n",
    "            w2d = (1/n) * np.dot(np.transpose(affordibility), (y_predicted - y_actual))\n",
    "\n",
    "            bias_d = np.mean(y_predicted - y_actual)\n",
    "\n",
    "            w1 = w1 - rate * w1d\n",
    "            w2 = w2 - rate * w2d\n",
    "            bias = bias - rate * bias_d\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                print(f\"Epoch: {i}/{epochs} - w1: {w1} - w2: {w2} - bias: {bias} - loss: {loss})\")\n",
    "\n",
    "            if loss <= loss_threshold:\n",
    "                print(f\"Epoch: {i}/{epochs} - w1: {w1} - w2: {w2} - bias: {bias} - loss: {loss})\")\n",
    "                break\n",
    "\n",
    "        return w1, w2, bias\n",
    "\n",
    "model_1 = DNN()\n",
    "model_1.fit(X_train_scaled, y_train, epochs=500, loss_threshold=0.4631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2     0.705020\n10    0.355836\n21    0.161599\n11    0.477919\n14    0.725586\n9     0.828987\ndtype: float64\n[[0.7054848 ]\n [0.35569546]\n [0.16827849]\n [0.47801176]\n [0.7260697 ]\n [0.8294984 ]]\n"
     ]
    }
   ],
   "source": [
    "# compare results between our own model vs tensorflow model (very similar)\n",
    "print(model_1.predict(X_test_scaled))\n",
    "print(model.predict(X_test_scaled))"
   ]
  }
 ]
}